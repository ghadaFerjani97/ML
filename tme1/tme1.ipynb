{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbres de décision, sélection de modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pydot non disponible pour l'affichage graphique, allez sur http://www.webgraphviz.com/ pour generer un apercu de l'arbre\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import decisiontree\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropie(vect):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropie_cond(list_vect):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data : tableau ( films , features ) , id2titles : dictionnaire id -> titre ,\n",
    "# fields : id feature -> nom\n",
    "[ data , id2titles , fields ]= pickle . load ( open (\" imdb_extrait . pkl \",\"rb\"))\n",
    "# la derniere colonne est le vote\n",
    "datax = data [: ,:32]\n",
    "datay = np . array ([1 if x [33] >6.5 else -1 for x in data ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expériences préliminaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decisiontree import DecisionTree\n",
    "dt = DecisionTree()\n",
    "dt.max_depth = 5 # on fixe la taille de l ’ arbre a 5\n",
    "dt.min_samples_split = 2 # nombre minimum d ’ exemples pour spliter un noeud\n",
    "dt.fit(datax, datay)\n",
    "dt.predict(datax[:5, :])\n",
    "print(dt.score(datax, datay))\n",
    "# dessine l ’ arbre dans un fichier pdf si pydot est installe .\n",
    "dt.to_pdf(\"/tmp/test_tree.pdf\", fields)\n",
    "# sinon utiliser http://www.webgraphviz.com/\n",
    "dt.to_dot(fields)\n",
    "# ou dans la console\n",
    "print(dt.print_tree(fields))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les scores augmentent avec la profondeur de l'arbre car l'apprentissage et le test se basent sur le même jeu de données. Ainsi, plus la profondeur est importante, plus on colle avec les données d'apprentissage (\"apprentissage par coeur\" ou sur apprentissage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces scores ne sont donc pas un indicateur fiable du comportement de l'algorithme sur des données réels. En effet, la généralisation se fera mal.\n",
    "<br/><br/>\n",
    "Pour obtenir un indicateur fiable, il faut séparer les données de test et d'apprentissage. Le but étant d'avoir assez de données pour bien apprendre, tout en ayant assez de données pour bien tester. Il faurdra aussi régler la condition d'arret du modèle (profondeur, entropie minimal, nombre d'élément à séparer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sur et sous apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsqu'il y a peu d'exemples d'apprentissage, le modèle est moins performant. Lorsqu'il y a peu d'exemples de test, la qualité du modèle est mal estimé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif est d'utiliser le plus de données possibles pour apprendre tout en ayant assez de données pour tester la qualité du modèle à généraliser.<br/>\n",
    "Un méthode pour faire ça est la validation croisée. On peut ainsi exploiter au maximum les données pour apprendre tout en ayant un bon recul sur la généralisation du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation croisée : sélection de modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
